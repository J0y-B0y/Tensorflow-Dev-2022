# -*- coding: utf-8 -*-
"""00_tensorflow_fundamentals.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XZGgvlUU_vl4HEu58O1t-l7zqd6rqyR6

### **In this notebook, we're going to cover some of the most fundamental concepts of tensors using TensorFlow**

##### *More specifically, we're going to cover:*
#####* Introduction to Tensors
#####* Getting information from Tensors
#####* Manipulating Tensors
#####* Tensors & NumPy
#####* Using @tf.function (a way to speed up your regular Python functions)
#####* Using GPUs with TensorFlow (or TPUs)
#####* Exercises to try for yourself

### Introduction to Tensors
"""

# Import TensorFlow
import tensorflow as tf
print(tf.__version__)

# Create tensors with tf.constant()
scalar = tf.constant(7)
scalar

# Check the number of dimensions of a tensor (ndim stands for number of dimensions)
scalar.ndim

# Create a vector
vector = tf.constant ([10, 10])
vector

# Check the dimension of our vector
vector.ndim

# Create a matrix (has more than 1 dimension)
matrix = tf.constant ([[10, 7],
                       [7, 10]])
matrix

# Check the dimension of our matrix
matrix.ndim

# Create another matrix
another_matrix = tf.constant([[10., 7.],
                              [3., 2.],
                              [8., 9.]], dtype=tf.float16) # Specify the data type with dtype parameter

another_matrix

# What's the number dimensions of another_matrix?
another_matrix.ndim

# Let's create a tensor
tensor = tf.constant ([[[1, 2, 3],
                        [4, 5, 6]],
                       [[7, 8, 9],
                        [10, 11, 12]],
                       [[13, 14, 15],
                        [16, 17, 18]]])
tensor

# What's the number dimensions of tensor?
tensor.ndim

"""###**What we've created so far:**

##### * Scalar: a single number
##### * Vector: a number with direction (e.g. wind speed and direction)
##### * Matrix: a 2-dimensional array of numbers
##### * Tensor: an n-dimensional array of numbers (when n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)

### Creating tensors with `tf.Variable`
"""

tf.Variable

# Create the same tensor with tf.Vairable() as above
changeable_tensor = tf.Variable([10, 7])
unchangeable_tensor = tf.constant([10, 7])
changeable_tensor, unchangeable_tensor

# Let's try change one of the elements in our changeable tensor
changeable_tensor[0] = 7
changeable_tensor

# How about we try .assign()
changeable_tensor[0].assign(7)
changeable_tensor

# Let's try change our unchangeable tensor
unchangeable_tensor[0].assign(7)
unchangeable_tensor

"""##### **Note**: Rarely in practice will you need to decide whether to use `tf.constant` or `tf.Variable` to create tensors, as Tensorflow does this for you. However, if in doubt, use `tf.constant` and change it later if needed.

### Creating random tensors

##### Random tensors are tensors of some arbitary size which contain random numbers.
"""

# Create two random (but the sam) tensors
random_1 = tf.random.Generator.from_seed(7) # set seed for reproducability
random_1 = random_1.normal(shape=(3, 2))
random_2 = tf.random.Generator.from_seed(7)
random_2 = random_2.normal(shape=(3, 2))

# Are they equal
random_1, random_2, random_1 == random_2

"""### Shuffle the order of elements in a tensor"""

# Shuffle a tensor (valuable for when you want to shuffle your data so the inherent order doesn't effect learning)
not_shuffled = tf.constant([[10, 7],
                            [3, 4],
                            [2, 5]])

# Shuffle our non-shuffled tensor
tf.random.shuffle(not_shuffled)

# Shuffle our non-shuffled tensor
tf.random.set_seed(42)
tf.random.shuffle(not_shuffled, seed=42)

not_shuffled

"""**EXERCISE**

##### ✍︎ **Exercise**: Read through TensorFlow documentation on random seed generation: https://www.tensorflow.org/api_docs/python/tf/random/set_seed and practice writing 5 random tensors and shuffle them.

##### It looks like if we want our shuffled tensors to be in the same order, we've got to use the global level random seed as well as the operation level random seed:

> Rule 4: If both the global and the operation seeds are set; both seeds are used in conjunction to determine the random sequence.
"""

# Shuffling the first tensor
tens1 = tf.constant([[10,7],
                    [40, 19],
                    [19, 100]]) 
tens1

tens1.ndim

tf.random.shuffle(tens1)

tf.random.set_seed(50)
tf.random.shuffle(tens1, seed=50)

# Experimenting with seeds
tf.random.set_seed(50)
tf.random.shuffle(tens1, seed=19)

# Shuffling the second tensor
tens2 = tf.constant([[99, 199, 50],
                     [99, 83, 695],
                     [75, 89, 22],
                     [65, 9999, 20]])
tens2

tens2.ndim

tf.random.shuffle(tens2)

tf.random.set_seed(99)
tf.random.shuffle(tens2, seed=99)

tf.random.shuffle(tens2, seed=1)

# Shuffling the third tensor
tens3 = ([[55, 67, 86, 99],
          [86, 96, 90],
          [85, 37, 84, 239, 49],
          [84, 93],
          [65, 90, 82]])
tens3

tens3.ndim

# Shuffling the fourth tensor
tens4 = tf.constant([[89, 80],
                     [90, 99],
                     [969, 6565],
                     [84, 754]])
tens4

tens4.ndim

tf.random.shuffle(tens4)

tf.random.set_seed(1092)
tf.random.shuffle(tens4, seed=1092)

# Experimentation with seed=
tf.random.set_seed(1092)
tf.random.shuffle(tens4, seed=1000)

# Shuffling the fifth tensor
tens5 = tf.constant([[98, 100, 1000, 10000],
                     [89, 90, 98, 987],
                     [89, 74, 822, 736]])
tens5

tens5.ndim

tf.random.shuffle(tens5)

tf.random.set_seed(9090)
tf.random.shuffle(tens5, seed=93)

tf.random.set_seed(42) # Global level random seed
tf.random.shuffle(not_shuffled, seed=42) # Operational level random seed

"""### Other ways to make tensors"""

# Create a tensor of all ones
tf.ones([10, 7])

# Create a tensor of all zeroes
tf.zeros(shape=(3,4))

"""### Turn NumPy arrays into tensors

##### The main difference between NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU (much faster for numerical computing)
"""

# You can also turn NumPy arrays into tensors
import numpy as np
numpy_A = np.arange(1, 25, dtype=np.int32) # create a NumPy array between 1 and 25
numpy_A

# X = tf.constant(some_matrix) # capital for matrix or tensor
# y = tf.constant(vector) # non capital for vector

A = tf.constant(numpy_A)
A

A = tf.constant(numpy_A, shape=(2, 3, 4))
B = tf.constant(numpy_A)
A, B

2 * 3 * 4

A = tf.constant(numpy_A, shape=(2, 3, 5))
B = tf.constant(numpy_A)
A, B

2 * 3 * 5

A = tf.constant(numpy_A, shape=(2, 2, 3, 2))
B = tf.constant(numpy_A)
A, B

A = tf.constant(numpy_A, shape=(3, 8))
B = tf.constant(numpy_A)
A, B

A.ndim

# Self-attempt
selfap = np.arange(1, 101, dtype=np.int32)
selfap

C = tf.constant(selfap)
C

C = tf.constant(selfap, shape=(50, 2))
D = tf.constant(selfap)
C, D

E = tf.constant(selfap, shape=(2, 2, 5, 5))
E, D

"""### Getting information from tensors

##### When dealing with tensors you probably want to be aware of the following attributes:
* Shape
* Rank
* Axis or Dimension
* Size
"""

# Create a rank 4 tensor (4 dimensions)
rank_4_tensor = tf.zeros([2, 3, 4, 5])
rank_4_tensor

rank_4_tensor[0]

rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)

2 * 3 * 4 * 5

# Get various attributes of our tensor
print("Datatype of every element:", rank_4_tensor.dtype)
print("Number of dimensions (rank):", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along the 0 axis", rank_4_tensor.shape[0])
print("Elements along the last axis", rank_4_tensor.shape[-1])
print("Total number of elements in our tensor", tf.size(rank_4_tensor).numpy())
print("Total number of elements in our tensor", tf.size(rank_4_tensor))

"""### Indexing Tensors

##### Tensors can be indexed just like Python lists
"""

some_list = [1, 2, 3, 4]
some_list[:2]

# Get the first two elements of each dimension
rank_4_tensor[:2, :2, :2, :2]

# Experimenting
rank_4_tensor[:2, :2]

some_list[:1]

rank_4_tensor.shape

# Get the first element from each dimension from each index except for the final one
rank_4_tensor[:1, :1, :1]

rank_4_tensor[:1, :1, :, :1]

# Create a rank 2 tensor(2 dimensions)
rank_2_tensor = tf.constant([[10, 7],
                             [3, 4]])
rank_2_tensor.shape, rank_2_tensor.ndim

rank_2_tensor

some_list, some_list[-1]

# Get the last item of each of row of our rank 2 tensor
rank_2_tensor[:, -1]

# Add in extra dimension to our rank 2 tensor
rank_3_tensor = rank_2_tensor[..., tf.newaxis]
rank_3_tensor

# Alternative to tf.newaxis
tf.expand_dims(rank_2_tensor, axis=-1) # "-1" means expand the final axis

tf.expand_dims(rank_2_tensor, axis=0) # expand the 0-axis

rank_2_tensor
